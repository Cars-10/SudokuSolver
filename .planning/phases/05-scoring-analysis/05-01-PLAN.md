---
phase: 05-scoring-analysis
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - Metrics/scoring-analysis.ts
  - Metrics/types.ts
  - package.json
autonomous: true

must_haves:
  truths:
    - "System calculates scores across 4 weight scenarios (100/0, 80/20, 50/50, 0/100)"
    - "System calculates rank positions for each language under each weight scenario"
    - "System computes max rank swing (best - worst rank) per language"
    - "System computes R^2 correlation between time and memory performance"
    - "System provides plain-English interpretation of correlation strength"
    - "System identifies statistical outliers using IQR method"
  artifacts:
    - path: "Metrics/scoring-analysis.ts"
      provides: "Statistical analysis functions for sensitivity, correlation, outliers"
      exports: ["calculateSensitivityScores", "calculateRankStability", "computeCorrelation", "interpretCorrelation", "identifyOutliers", "calculatePercentiles"]
    - path: "Metrics/types.ts"
      provides: "Type definitions for sensitivity and outlier analysis"
      contains: "SensitivityResult, RankStabilityResult, CorrelationResult, OutlierAnalysis"
  key_links:
    - from: "Metrics/scoring-analysis.ts:calculateSensitivityScores()"
      to: "Metrics/scoring.ts:calculateOverallScore()"
      via: "import and parameterized weight scenarios"
      pattern: "calculateOverallScore.*weights"
    - from: "Metrics/scoring-analysis.ts:identifyOutliers()"
      to: "simple-statistics:interquartileRange"
      via: "import for IQR-based outlier detection"
      pattern: "interquartileRange"
---

<objective>
Create the scoring analysis module with functions for sensitivity analysis, correlation computation, and outlier detection.

Purpose: Provide the statistical computation foundation that HTMLGenerator.ts will use to display score insights. This separates analysis logic from rendering logic for clean architecture.

Output: New `Metrics/scoring-analysis.ts` file with exported analysis functions, updated `Metrics/types.ts` with result types, and simple-statistics dependency installed.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Phase-specific context
@.planning/phases/05-scoring-analysis/05-CONTEXT.md
@.planning/phases/05-scoring-analysis/05-RESEARCH.md

# Existing scoring implementation
@Metrics/scoring.ts
@Metrics/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install simple-statistics and add type definitions</name>
  <files>package.json, Metrics/types.ts</files>
  <action>
1. Install simple-statistics library:
   ```bash
   cd /Users/vibe/ClaudeCode/SudokuSolver && npm install simple-statistics
   ```

2. Add new type definitions to `Metrics/types.ts` for analysis results:

   ```typescript
   // Sensitivity Analysis Types
   export interface WeightScenario {
       name: string;
       weights: { time: number; memory: number };
   }

   export interface ScenarioResult {
       scenario: string;
       score: number;
       rank: number;
   }

   export interface SensitivityResult {
       language: string;
       scenarios: ScenarioResult[];
   }

   export interface RankStabilityResult {
       language: string;
       maxSwing: number;
       bestRank: number;
       worstRank: number;
       currentRank: number;  // Rank under current 80/20 weighting
   }

   // Correlation Analysis Types
   export interface CorrelationResult {
       rValue: number;
       rSquared: number;
       interpretation: string;
   }

   // Outlier Analysis Types
   export interface OutlierAnalysis {
       language: string;
       metric: 'time' | 'memory' | 'score';
       value: number;
       threshold: number;
       direction: 'high' | 'low';
       explanation: string;
   }

   // Percentile Analysis Types
   export interface PercentileResult {
       p25: number;
       p50: number;  // Median
       p75: number;
       p90: number;
       p99: number;
   }
   ```

   Add these types AFTER the existing SolverMetrics interface definition.
  </action>
  <verify>
Run: `grep -c "simple-statistics" package.json`
Expected: 1 match (in dependencies)

Run: `grep -c "SensitivityResult\|CorrelationResult\|OutlierAnalysis" Metrics/types.ts`
Expected: At least 3 matches (interface definitions)

Run: `npx tsc --noEmit Metrics/types.ts`
Expected: No type errors (exit code 0)
  </verify>
  <done>
simple-statistics installed in package.json, and Metrics/types.ts contains new interfaces: WeightScenario, ScenarioResult, SensitivityResult, RankStabilityResult, CorrelationResult, OutlierAnalysis, PercentileResult
  </done>
</task>

<task type="auto">
  <name>Task 2: Create scoring-analysis.ts with sensitivity and rank stability functions</name>
  <files>Metrics/scoring-analysis.ts</files>
  <action>
Create new file `Metrics/scoring-analysis.ts` with sensitivity analysis functions:

```typescript
import { sampleCorrelation, linearRegression, linearRegressionLine, rSquared, quantile, interquartileRange } from 'simple-statistics';
import { calculateOverallScore } from './scoring.ts';
import type { SolverMetrics, MetricResult, WeightScenario, ScenarioResult, SensitivityResult, RankStabilityResult, CorrelationResult, OutlierAnalysis, PercentileResult } from './types.ts';

// Weight scenarios for sensitivity analysis
export const WEIGHT_SCENARIOS: WeightScenario[] = [
    { name: 'Time Only', weights: { time: 1.0, memory: 0.0 } },
    { name: 'Current (80/20)', weights: { time: 0.8, memory: 0.2 } },
    { name: 'Balanced (50/50)', weights: { time: 0.5, memory: 0.5 } },
    { name: 'Memory Only', weights: { time: 0.0, memory: 1.0 } }
];

/**
 * Calculate scores for all languages across all weight scenarios.
 * Returns a map of language -> array of scenario results.
 */
export function calculateSensitivityScores(
    metrics: SolverMetrics[],
    cResults: MetricResult[]
): Map<string, ScenarioResult[]> {
    const resultsByLanguage = new Map<string, ScenarioResult[]>();

    WEIGHT_SCENARIOS.forEach(scenario => {
        // Calculate scores for all languages under this scenario
        const languageScores = metrics.map(m => ({
            language: m.solver,
            score: calculateOverallScore(m.results, cResults, scenario.weights)
        }));

        // Sort by score (lower is better) and assign ranks
        languageScores.sort((a, b) => a.score - b.score);

        languageScores.forEach((lang, index) => {
            const rank = index + 1;
            if (!resultsByLanguage.has(lang.language)) {
                resultsByLanguage.set(lang.language, []);
            }
            resultsByLanguage.get(lang.language)!.push({
                scenario: scenario.name,
                score: lang.score,
                rank
            });
        });
    });

    return resultsByLanguage;
}

/**
 * Calculate rank stability metrics for all languages.
 * Max swing = worst rank - best rank across all scenarios.
 */
export function calculateRankStability(
    sensitivityResults: Map<string, ScenarioResult[]>
): RankStabilityResult[] {
    const stability: RankStabilityResult[] = [];

    for (const [language, scenarios] of sensitivityResults.entries()) {
        const ranks = scenarios.map(s => s.rank);
        const bestRank = Math.min(...ranks);
        const worstRank = Math.max(...ranks);
        const maxSwing = worstRank - bestRank;

        // Find current rank (80/20 scenario)
        const currentScenario = scenarios.find(s => s.scenario === 'Current (80/20)');
        const currentRank = currentScenario?.rank ?? 0;

        stability.push({ language, maxSwing, bestRank, worstRank, currentRank });
    }

    // Sort by max swing (descending) to find most unstable
    stability.sort((a, b) => b.maxSwing - a.maxSwing);

    return stability;
}

/**
 * Convert sensitivity map to array format for easier consumption.
 */
export function sensitivityMapToArray(
    sensitivityMap: Map<string, ScenarioResult[]>
): SensitivityResult[] {
    const results: SensitivityResult[] = [];
    for (const [language, scenarios] of sensitivityMap.entries()) {
        results.push({ language, scenarios });
    }
    return results;
}
```
  </action>
  <verify>
Run: `grep -c "calculateSensitivityScores\|calculateRankStability" Metrics/scoring-analysis.ts`
Expected: At least 2 matches (function definitions)

Run: `grep "WEIGHT_SCENARIOS" Metrics/scoring-analysis.ts | head -1`
Expected: Shows the exported constant definition

Run: `npx tsc --noEmit Metrics/scoring-analysis.ts`
Expected: No type errors (exit code 0)
  </verify>
  <done>
Metrics/scoring-analysis.ts contains:
- WEIGHT_SCENARIOS constant with 4 scenarios (100/0, 80/20, 50/50, 0/100)
- calculateSensitivityScores() computes scores and ranks for all languages across scenarios
- calculateRankStability() computes max swing, best/worst rank per language
- sensitivityMapToArray() helper for format conversion
  </done>
</task>

<task type="auto">
  <name>Task 3: Add correlation, outlier, and percentile analysis functions</name>
  <files>Metrics/scoring-analysis.ts</files>
  <action>
Add the remaining analysis functions to `Metrics/scoring-analysis.ts` (append after existing functions):

```typescript
/**
 * Compute Pearson correlation coefficient and R^2 between time and memory.
 * R^2 indicates how much variance in memory is explained by time.
 */
export function computeCorrelation(metrics: SolverMetrics[]): CorrelationResult {
    // Extract total time and memory for each language
    const timeData: number[] = [];
    const memoryData: number[] = [];

    metrics.forEach(m => {
        const totalTime = m.results.reduce((acc, r) => acc + r.time, 0);
        const maxMemory = Math.max(...m.results.map(r => r.memory));
        if (totalTime > 0 && maxMemory > 0) {
            timeData.push(totalTime);
            memoryData.push(maxMemory);
        }
    });

    // Need at least 3 data points for meaningful correlation
    if (timeData.length < 3) {
        return {
            rValue: 0,
            rSquared: 0,
            interpretation: 'Insufficient data for correlation analysis (need at least 3 languages with valid results).'
        };
    }

    // Calculate Pearson correlation coefficient
    const rValue = sampleCorrelation(timeData, memoryData);

    // Calculate R^2 using linear regression
    const samples = timeData.map((t, i) => [t, memoryData[i]] as [number, number]);
    const regression = linearRegression(samples);
    const regressionLine = linearRegressionLine(regression);
    const r2 = rSquared(samples, regressionLine);

    // Generate interpretation
    const interpretation = interpretCorrelation(r2);

    return { rValue, rSquared: r2, interpretation };
}

/**
 * Provide plain-English interpretation of R^2 correlation value.
 */
export function interpretCorrelation(r2: number): string {
    if (isNaN(r2)) {
        return 'Correlation could not be computed (data may have zero variance).';
    }

    if (r2 >= 0.8) {
        return `R² = ${r2.toFixed(2)} indicates a very strong correlation between time and memory performance. Languages that are fast tend to also be memory-efficient.`;
    } else if (r2 >= 0.5) {
        return `R² = ${r2.toFixed(2)} indicates a moderate correlation between time and memory performance. There's a noticeable relationship, but other factors also influence memory usage.`;
    } else if (r2 >= 0.3) {
        return `R² = ${r2.toFixed(2)} indicates a weak correlation between time and memory performance. Time and memory efficiency are somewhat independent characteristics.`;
    } else {
        return `R² = ${r2.toFixed(2)} indicates little to no correlation between time and memory performance. Being fast doesn't predict memory efficiency in this benchmark suite.`;
    }
}

/**
 * Identify statistical outliers using IQR method.
 * IQR is more robust than Z-score for non-normal (skewed) distributions.
 */
export function identifyOutliers(metrics: SolverMetrics[]): OutlierAnalysis[] {
    const outliers: OutlierAnalysis[] = [];

    // Extract total time and max memory for each language
    const timeValues = metrics.map(m => ({
        language: m.solver,
        value: m.results.reduce((acc, r) => acc + r.time, 0)
    })).filter(t => t.value > 0);

    const memoryValues = metrics.map(m => ({
        language: m.solver,
        value: Math.max(...m.results.map(r => r.memory))
    })).filter(m => m.value > 0);

    // Detect time outliers
    const timeOutliers = detectOutliersIQR(timeValues, 'time');
    outliers.push(...timeOutliers);

    // Detect memory outliers
    const memoryOutliers = detectOutliersIQR(memoryValues, 'memory');
    outliers.push(...memoryOutliers);

    return outliers;
}

/**
 * Internal helper for IQR-based outlier detection.
 * Outliers are values below Q1 - 1.5*IQR or above Q3 + 1.5*IQR.
 */
function detectOutliersIQR(
    data: Array<{ language: string; value: number }>,
    metricType: 'time' | 'memory' | 'score'
): OutlierAnalysis[] {
    const outliers: OutlierAnalysis[] = [];

    if (data.length < 4) return outliers; // Need enough data for quartiles

    const values = data.map(d => d.value);

    // Calculate quartiles
    const q1 = quantile(values, 0.25);
    const q3 = quantile(values, 0.75);
    const iqr = interquartileRange(values);

    // IQR outlier thresholds
    const lowerBound = q1 - 1.5 * iqr;
    const upperBound = q3 + 1.5 * iqr;

    // Check each value
    data.forEach(({ language, value }) => {
        if (value < lowerBound) {
            outliers.push({
                language,
                metric: metricType,
                value,
                threshold: lowerBound,
                direction: 'low',
                explanation: `Exceptionally fast ${metricType} performance (below Q1 - 1.5×IQR threshold of ${lowerBound.toFixed(2)})`
            });
        } else if (value > upperBound) {
            outliers.push({
                language,
                metric: metricType,
                value,
                threshold: upperBound,
                direction: 'high',
                explanation: `Unusually slow ${metricType} performance (above Q3 + 1.5×IQR threshold of ${upperBound.toFixed(2)})`
            });
        }
    });

    return outliers;
}

/**
 * Calculate percentiles for a dataset.
 * Useful for understanding score distribution.
 */
export function calculatePercentiles(data: number[]): PercentileResult {
    if (data.length === 0) {
        return { p25: 0, p50: 0, p75: 0, p90: 0, p99: 0 };
    }

    return {
        p25: quantile(data, 0.25),
        p50: quantile(data, 0.50),  // Median
        p75: quantile(data, 0.75),
        p90: quantile(data, 0.90),
        p99: quantile(data, 0.99)
    };
}

/**
 * Get score percentiles for all languages.
 */
export function getScorePercentiles(metrics: SolverMetrics[]): PercentileResult {
    const scores = metrics
        .map(m => m.score)
        .filter((s): s is number => s !== undefined && s > 0);

    return calculatePercentiles(scores);
}
```
  </action>
  <verify>
Run: `grep -c "computeCorrelation\|identifyOutliers\|calculatePercentiles" Metrics/scoring-analysis.ts`
Expected: At least 3 matches (function definitions)

Run: `grep "interquartileRange\|sampleCorrelation" Metrics/scoring-analysis.ts | head -2`
Expected: Shows imports from simple-statistics

Run: `npx tsc --noEmit Metrics/scoring-analysis.ts`
Expected: No type errors (exit code 0)

Run: `node -e "import('./Metrics/scoring-analysis.ts').then(m => console.log(Object.keys(m).length + ' exports'))" 2>/dev/null || npx ts-node -e "import('./Metrics/scoring-analysis.ts').then(m => console.log(Object.keys(m).length + ' exports'))"`
Expected: Shows number of exports (should be 8+)
  </verify>
  <done>
Metrics/scoring-analysis.ts contains complete analysis module:
- computeCorrelation() computes Pearson R and R^2 with plain-English interpretation
- interpretCorrelation() provides accessible explanation of R^2 values
- identifyOutliers() uses IQR method (Q1 - 1.5*IQR, Q3 + 1.5*IQR thresholds)
- calculatePercentiles() and getScorePercentiles() for distribution analysis
All functions properly typed and importing from simple-statistics
  </done>
</task>

</tasks>

<verification>
After all tasks complete, verify the complete analysis module:

1. **Dependency installed:** simple-statistics in package.json dependencies
2. **Types defined:** SensitivityResult, CorrelationResult, OutlierAnalysis in types.ts
3. **Module compiles:** `npx tsc --noEmit Metrics/scoring-analysis.ts` succeeds
4. **Exports work:** All 8+ functions exported and importable
5. **Weight scenarios:** WEIGHT_SCENARIOS contains 4 scenarios with correct weights

Run complete verification:
```bash
cd /Users/vibe/ClaudeCode/SudokuSolver

# Check dependency
grep "simple-statistics" package.json

# Check types
grep -E "export interface (Sensitivity|Correlation|Outlier)" Metrics/types.ts

# Compile check
npx tsc --noEmit Metrics/scoring-analysis.ts && echo "COMPILE OK"

# Count exports
grep "^export " Metrics/scoring-analysis.ts | wc -l

# Verify weight scenarios
grep -A4 "WEIGHT_SCENARIOS" Metrics/scoring-analysis.ts | head -6
```
</verification>

<success_criteria>
1. simple-statistics library installed in package.json
2. Metrics/types.ts contains all new interface definitions (WeightScenario, ScenarioResult, SensitivityResult, RankStabilityResult, CorrelationResult, OutlierAnalysis, PercentileResult)
3. Metrics/scoring-analysis.ts exports: WEIGHT_SCENARIOS, calculateSensitivityScores, calculateRankStability, sensitivityMapToArray, computeCorrelation, interpretCorrelation, identifyOutliers, calculatePercentiles, getScorePercentiles
4. Module compiles without TypeScript errors
5. Sensitivity analysis covers 4 weight scenarios: Time Only (100/0), Current (80/20), Balanced (50/50), Memory Only (0/100)
6. Correlation function uses simple-statistics sampleCorrelation and rSquared
7. Outlier detection uses IQR method (not Z-score) with 1.5*IQR threshold
8. All functions handle edge cases (empty data, insufficient points for correlation)
</success_criteria>

<output>
After completion, create `.planning/phases/05-scoring-analysis/05-01-SUMMARY.md`
</output>
